{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t-sijoshi/miniconda3/envs/vlm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.85s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "# The line `model_id = \"/home/t-sijoshi/multimodal-data-gen/output/spatial_map_500_canonical_vt_ft\"` is assigning a specific path to a directory or file to the variable `model_id`. This path likely points to a pre-trained model or model checkpoint stored on the local file system. The code may be attempting to load a pre-trained model from the specified directory for further processing or fine-tuning.\n",
    "model_id = \"/home/t-sijoshi/multimodal-data-gen/output/spatial_map_500_canonical_vt_ft\"\n",
    "model_id  = \"microsoft/Phi-3-vision-128k-instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=f\"cuda:{DEVICE_NUM}\", trust_remote_code=True, torch_dtype=torch.float16, _attn_implementation=\"eager\")\n",
    "\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|human|>\n",
      " The user asks a multiple choice question on spatial reasoning given a figure.\n",
      "                 Please rate the accuracy of the AI Answer compared to the Correct answer.\n",
      "                 The assistant receives a binary score for the answer, of 0 or 1, where 1 means the answer is correct, 0 means incorrect answer.\n",
      "                 Please output only 0 or 1 indicating whether the answer from the AI is correct or not.                 Options:                 A A black person living in Canada                 B People whose ancestors came to Canada through the slave trade                 C A white person who originated in Africa and now lives in Canada                 D Any of the above                 Correct: D                 AI Answer: B<|end|>\n",
      "<|assistant|>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "query = \" The user asks a multiple choice question on spatial reasoning given a figure.\\n \\\n",
    "                Please rate the accuracy of the AI Answer compared to the Correct answer.\\n \\\n",
    "                The assistant receives a binary score for the answer, of 0 or 1, where 1 means the answer is correct, 0 means incorrect answer.\\n \\\n",
    "                Please output only 0 or 1 indicating whether the answer from the AI is correct or not. \\\n",
    "                Options: \\\n",
    "                A A black person living in Canada \\\n",
    "                B People whose ancestors came to Canada through the slave trade \\\n",
    "                C A white person who originated in Africa and now lives in Canada \\\n",
    "                D Any of the above \\\n",
    "                Correct: D \\\n",
    "                AI Answer: B\"\n",
    "\n",
    "# image = Image.open(\"/home/t-sijoshi/multimodal-data-gen/downloaded_datasets/spatial_map_canonical_500/images/map_2000.png\")#\n",
    "# display(image.resize((256,256)))\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"human\", \"content\": f\"{query}\"},\n",
    "]\n",
    "\n",
    "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(prompt)\n",
    "inputs = processor(prompt,  return_tensors=\"pt\").to(f\"cuda:{DEVICE_NUM}\")\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 10,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
    "\n",
    "# remove input tokens\n",
    "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/t-sijoshi/multimodal-data-gen/results/spatial_map_v0_2024_07_16_00:53:59.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/t-sijoshi/multimodal-data-gen/downloaded_datasets/spatial_map_visual_only_v0/data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      9\u001b[0m   correct_reader \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m---> 10\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mjsonlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/t-sijoshi/multimodal-data-gen/results/spatial_map_v0_2024_07_16_00:53:59.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ai_reader:\n\u001b[1;32m     11\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mzip\u001b[39m(correct_reader, ai_reader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(correct_reader))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m datum, result \u001b[38;5;129;01min\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/miniconda3/envs/vlm/lib/python3.10/site-packages/jsonlines/jsonlines.py:643\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(file, mode, loads, dumps, compact, sort_keys, flush)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m Reader \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m Writer\n\u001b[1;32m    642\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 643\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    645\u001b[0m     loads\u001b[38;5;241m=\u001b[39mloads,\n\u001b[1;32m    646\u001b[0m     dumps\u001b[38;5;241m=\u001b[39mdumps,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m     flush\u001b[38;5;241m=\u001b[39mflush,\n\u001b[1;32m    650\u001b[0m )\n\u001b[1;32m    651\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/t-sijoshi/multimodal-data-gen/results/spatial_map_v0_2024_07_16_00:53:59.jsonl'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import json \n",
    "from tqdm import tqdm \n",
    "import jsonlines\n",
    "\n",
    "num_total = 0\n",
    "num_correct = 0\n",
    "with open(\"/home/t-sijoshi/multimodal-data-gen/downloaded_datasets/spatial_map_visual_only_v0/data.json\", \"r\") as file:\n",
    "  correct_reader = json.load(file)\n",
    "  with jsonlines.open(\"/home/t-sijoshi/multimodal-data-gen/results/spatial_map_v0_2024_07_16_00:53:59.jsonl\") as ai_reader:\n",
    "    pbar = tqdm(zip(correct_reader, ai_reader), total=len(correct_reader))\n",
    "    for datum, result in pbar:\n",
    "      correct = datum[\"conversations\"][1][\"value\"]\n",
    "      num_total += len(correct)\n",
    "      ai_answer = result[\"response\"]\n",
    "      query = f\"We would like to request your feedback on the performance of an AI assistant.\\n \\\n",
    "          The user asks the question on spatial reasoning given a figure.\\n \\\n",
    "          Please rate the accuracy of the AI assistant answer compared to the Correct answer.\\n \\\n",
    "          The assistant receives an binary score for each answer, of 0 or 1, where 1 means the answer is correct, 0 means incorrect answer.\\n \\\n",
    "          The total score is the sum of the binary scores for each answer \\n \\\n",
    "          Answers are denoted by A1, A2 and so on.\\n \\\n",
    "          Please first output a single line containing only a value indicating the total scores for Assistant\\n \\\n",
    "          Correct: {str(correct)}\\n \\\n",
    "          AI Answer: {str(ai_answer)}\"\n",
    "\n",
    "      messages = [\n",
    "          {\"role\": \"user\", \"content\": f\"{query}\"},\n",
    "      ]\n",
    "\n",
    "      prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "      inputs = processor(prompt, return_tensors=\"pt\").to(f\"cuda:{DEVICE_NUM}\")\n",
    "      generation_args = {\n",
    "          \"max_new_tokens\": 1000,\n",
    "          #\"temperature\": 0.0,\n",
    "          \"do_sample\": False,\n",
    "      }\n",
    "\n",
    "      generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
    "\n",
    "      # remove input tokens\n",
    "      generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "      response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "      num_correct += int(response)\n",
    "      \n",
    "      pbar.set_postfix({\"acc\": num_correct / num_total})\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(num_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
